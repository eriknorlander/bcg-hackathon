{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('avocado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'Date' has 169 unique categories\n",
      "Feature 'type' has 2 unique categories, which are ['conventional' 'organic']\n",
      "Feature 'region' has 54 unique categories\n"
     ]
    }
   ],
   "source": [
    "# simple way to check the contents of categorical features\n",
    "def feature_check(X):\n",
    "    cat_cols = np.array([])\n",
    "    for col_name in X.columns:\n",
    "        if X[col_name].dtypes == 'object':\n",
    "            unique_cat = len(X[col_name].unique())\n",
    "            cat_cols = np.hstack([np.array(col_name), cat_cols])\n",
    "            if unique_cat > 10:\n",
    "                print(\"Feature '{col_name}' has {unique_cat} unique categories\".format(\n",
    "                        col_name=col_name, unique_cat=unique_cat))\n",
    "            else:\n",
    "                print(\"Feature '{col_name}' has {unique_cat} unique categories, which are {c}\".format(\n",
    "                    col_name=col_name, unique_cat=unique_cat,c=X[col_name].unique()))\n",
    "    return cat_cols\n",
    "  \n",
    "cat_cols = feature_check(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(y_test, y_score):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    y_test = pd.get_dummies(y_test).values\n",
    "    (_, n_classes) = y_test.shape\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score[:,1])\n",
    "\n",
    "plt.plot(thresholds, precision[1:], label='precision')\n",
    "plt.plot(thresholds, recall[1:], label='recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import lgamma\n",
    "from numba import jit\n",
    "\n",
    "#defining the functions used\n",
    "@jit\n",
    "def h(a, b, c, d):\n",
    "    num = lgamma(a + c) + lgamma(b + d) + lgamma(a + b) + lgamma(c + d)\n",
    "    den = lgamma(a) + lgamma(b) + lgamma(c) + lgamma(d) + lgamma(a + b + c + d)\n",
    "    return np.exp(num - den)\n",
    "\n",
    "@jit\n",
    "def g0(a, b, c):    \n",
    "    return np.exp(lgamma(a + b) + lgamma(a + c) - (lgamma(a + b + c) + lgamma(a)))\n",
    "\n",
    "@jit\n",
    "def hiter(a, b, c, d):\n",
    "    while d > 1:\n",
    "        d -= 1\n",
    "        yield h(a, b, c, d) / d\n",
    "\n",
    "def g(a, b, c, d):\n",
    "    return g0(a, b, c) + sum(hiter(a, b, c, d))\n",
    "\n",
    "def calc_prob_between(beta1, beta2):\n",
    "    return g(beta1.args[0], beta1.args[1], beta2.args[0], beta2.args[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test option lift Conversion Rates by 10.71% with 65.3% probability.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import beta\n",
    "import numpy as np\n",
    "#from calc_prob import calc_prob_between\n",
    "\n",
    "#This is the known data: impressions and conversions for the Control and Test set\n",
    "imps_ctrl, convs_ctrl = 17000, 27 \n",
    "imps_test, convs_test = 17000, 30\n",
    "\n",
    "#here we create the Beta functions for the two sets\n",
    "a_C, b_C = convs_ctrl + 1, imps_ctrl-convs_ctrl+1\n",
    "beta_C = beta(a_C, b_C)\n",
    "a_T, b_T = convs_test + 1, imps_test-convs_test+1\n",
    "beta_T = beta(a_T, b_T)\n",
    "\n",
    "#calculating the lift\n",
    "lift=(beta_T.mean()-beta_C.mean())/beta_C.mean()\n",
    "\n",
    "#calculating the probability for Test to be better than Control\n",
    "prob=calc_prob_between(beta_T, beta_C)\n",
    "\n",
    "print (f\"Test option lift Conversion Rates by {lift*100:2.2f}% with {prob*100:2.1f}% probability.\")\n",
    "#output: Test option lift Conversion Rates by 59.68% with 98.2% probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
